{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637ddd60",
   "metadata": {},
   "source": [
    "## Initialize a new Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-10 18:03:56.664\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mutils.chat_history\u001b[0m:\u001b[36mremove_unlisted_chats\u001b[0m:\u001b[36m205\u001b[0m - \u001b[33m\u001b[1mRemoving Unlisted Chat: 18ffc144-d033-4fc5-b5e1-f66921c2f40e\u001b[0m\n",
      "\u001b[32m2025-07-10 18:03:56.665\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mutils.chat_history\u001b[0m:\u001b[36mremove_unlisted_chats\u001b[0m:\u001b[36m205\u001b[0m - \u001b[33m\u001b[1mRemoving Unlisted Chat: 95c6a153-f7eb-4e22-a075-0e24f18c5b44\u001b[0m\n",
      "\u001b[32m2025-07-10 18:03:56.666\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mutils.chat_history\u001b[0m:\u001b[36mremove_unlisted_chats\u001b[0m:\u001b[36m209\u001b[0m - \u001b[31m\u001b[1mChat: 95c6a153-f7eb-4e22-a075-0e24f18c5b44 is non-existent!\u001b[0m\n",
      "\u001b[32m2025-07-10 18:03:56.666\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mutils.chat_history\u001b[0m:\u001b[36mremove_unlisted_chats\u001b[0m:\u001b[36m205\u001b[0m - \u001b[33m\u001b[1mRemoving Unlisted Chat: 74c0961d-2f87-448b-abcf-cbe751bd614d\u001b[0m\n",
      "\u001b[32m2025-07-10 18:03:56.666\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mutils.chat_history\u001b[0m:\u001b[36mremove_unlisted_chats\u001b[0m:\u001b[36m209\u001b[0m - \u001b[31m\u001b[1mChat: 74c0961d-2f87-448b-abcf-cbe751bd614d is non-existent!\u001b[0m\n",
      "\u001b[32m2025-07-10 18:03:56.667\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mutils.chat_history\u001b[0m:\u001b[36mremove_unlisted_chats\u001b[0m:\u001b[36m205\u001b[0m - \u001b[33m\u001b[1mRemoving Unlisted Chat: 3af7c60f-6458-442a-b0ed-ec173c6d667a\u001b[0m\n",
      "\u001b[32m2025-07-10 18:03:56.667\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mutils.chat_history\u001b[0m:\u001b[36mremove_unlisted_chats\u001b[0m:\u001b[36m209\u001b[0m - \u001b[31m\u001b[1mChat: 3af7c60f-6458-442a-b0ed-ec173c6d667a is non-existent!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ID: ebe0960e-eec1-4253-80aa-d870bce63e8d\n"
     ]
    }
   ],
   "source": [
    "from intellitube.utils import ChatHistoryManager\n",
    "chat: ChatHistoryManager = ChatHistoryManager.new_chat()\n",
    "print(f\"Chat ID:\", chat.chat_id)\n",
    "\n",
    "chat.remove_unlisted_chats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5e8681",
   "metadata": {},
   "source": [
    "## Initialize the RAG System\n",
    "Using `TextDocumentRAG()` from `intellitube.rag` module automatically initializes `Qdrant` client as Vector Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from intellitube.rag import TextDocumentRAG\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_rag = TextDocumentRAG(\n",
    "    path_on_disk=chat.chat_dirpath,\n",
    "    collection_path_on_disk=os.path.join(chat.chat_dirpath, \"collection\"),\n",
    "    collection_name=chat.chat_id,\n",
    ")\n",
    "\n",
    "def add_to_vdb(docuemnts: List[Document]) -> None:\n",
    "    # convert to a list of document(s) if not already!\n",
    "    if type(docuemnts) == Document:\n",
    "        docuemnts = [docuemnts]\n",
    "    \n",
    "    document_rag.add_documents(\n",
    "        docuemnts, split_text=True,\n",
    "        split_config={\n",
    "            \"chunk_size\": 512,\n",
    "            \"chunk_overlap\": 128\n",
    "        },\n",
    "        skip_if_collection_exists=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0781f4",
   "metadata": {},
   "source": [
    "## Create Document Loader Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e792db4",
   "metadata": {},
   "source": [
    "### 1. Add YouTube Videos to the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd262d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    YTContentData,\n",
    "    webvtt_2_str,\n",
    "    download_youtube_audio_or_transcript,\n",
    ")\n",
    "\n",
    "test_url = \"https://www.youtube.com/watch?v=W3I3kAg2J7w&t=231s\"\n",
    "\n",
    "# @tool\n",
    "def load_youtube_transcript(youtube_url: str) -> str:\n",
    "    \"\"\"Load the given YouTube video's transcript to the vector database.\n",
    "    It is required to answer user-queries based on the the Transcript context.\"\"\"\n",
    "\n",
    "    print(\"Loading Youtube Transcript...\")\n",
    "    \n",
    "    # download the youtube transcript (or audio if transcript not available)\n",
    "    yt_video_data: YTContentData = download_youtube_audio_or_transcript(\n",
    "        video_url=youtube_url,\n",
    "    )\n",
    "\n",
    "    # convert the WEBVTT format trancript to a plain text string\n",
    "    vtt_str = webvtt_2_str(vtt_file_path=yt_video_data.transcript_path)\n",
    "    \n",
    "    print(vtt_str[:100])    # print first 100 characters\n",
    "\n",
    "    # add the transcript-string to the vector database\n",
    "    add_to_vdb(Document(vtt_str))\n",
    "    return \"YouTube Video Transcript has been loaded successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac44794",
   "metadata": {},
   "source": [
    "### 2. Add PDF/Text Documents to the Vector Dataabse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33961ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# @tool\n",
    "def load_document(document_path: str) -> str:\n",
    "    \"\"\"Load the given Document's content to the vector database.\n",
    "    It is required to answer user-queries based on the the Document context.\"\"\"\n",
    "    print(\"Loading Document...\")\n",
    "    \n",
    "    ext = os.path.splitext(document_path)[1][1:].lower()\n",
    "    documents: List[Document]\n",
    "\n",
    "    if ext == 'pdf':\n",
    "        documents = PyPDFLoader(document_path).load()\n",
    "    elif ext == 'txt':\n",
    "        with open(document_path, 'r') as file:\n",
    "            documents = [Document(\n",
    "                page_content=file.read(),\n",
    "                metadata={ \"source\": document_path }\n",
    "            )]\n",
    "    else:\n",
    "        return f\"Unsupported filetype: {ext}!\"\n",
    "    \n",
    "    add_to_vdb(documents)\n",
    "    return \"The document has been loaded successfully!\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8cdd0",
   "metadata": {},
   "source": [
    "### 3. Add WebPages as Documents to the Vector Dataabse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08fccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# @tool\n",
    "def load_webpage(webpage_url: str) -> str:\n",
    "    \"\"\"Load the given WebSite's content to the vector database.\n",
    "    It is required to answer user-queries based on the the WebPage's context.\"\"\"\n",
    "\n",
    "    add_to_vdb(WebBaseLoader(webpage_url).load())\n",
    "    print(\"Loading Webpage...\")\n",
    "    return \"The webpage has been loaded successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a268bf2a",
   "metadata": {},
   "source": [
    "### Pass the Query Tool\n",
    "This is a function to be called by the Agent if none of the other tools can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool\n",
    "def pass_user_query(user_query: str) -> None:\n",
    "    \"\"\"Use this tool when none of the other tools are useful.\"\"\"\n",
    "    print(f\"Passes User Query: {user_query}\")\n",
    "    return f\"User: {user_query}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c1f488",
   "metadata": {},
   "source": [
    "#### Finally, compile a list of the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_loader_tools = [load_youtube_transcript, load_document, load_webpage, pass_user_query]\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(document_loader_tools)\n",
    "\n",
    "document_loader_functions = {\n",
    "    \"document\": load_document,\n",
    "    \"youtube_video\": load_youtube_transcript,\n",
    "    \"website\": load_webpage\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0d559",
   "metadata": {},
   "source": [
    "## Choose an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional\n",
    "# from langchain.chat_models import init_chat_model\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def select_llm(\n",
    "    model_provider: Literal['openai', 'groq', 'nvidia', 'google', 'ollama'],\n",
    "    model_name: Optional[str] = None,\n",
    "    temperature: float = 0.0,\n",
    ") -> BaseChatModel:\n",
    "    if model_provider == 'openai':\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        return ChatOpenAI(model=model_name or \"gpt-4o-mini\", temperature=temperature)\n",
    "    elif model_provider == 'groq':\n",
    "        from langchain_groq import ChatGroq\n",
    "        return ChatGroq(model=model_name or \"llama-3.3-70b-versatile\", temperature=temperature)\n",
    "    elif model_provider == 'nvidia':\n",
    "        from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "        return ChatNVIDIA(model=model_name or \"mistralai/mistral-small-24b-instruct\", temperature=temperature)\n",
    "        # return ChatNVIDIA(model=model_name or \"nvidia/llama-3.1-nemotron-51b-instruct\", temperature=temperature)\n",
    "    elif model_provider == 'google':\n",
    "        from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "        return ChatGoogleGenerativeAI(model=model_name or \"gemini-2.0-flash\", temperature=temperature)\n",
    "    elif model_provider == 'ollama':\n",
    "        from langchain_ollama import ChatOllama\n",
    "        # return ChatOllama(model=model_name or \"granite3.3:8b\", temperature=temperature)\n",
    "        return ChatOllama(model=model_name or \"llama3.2:3b\", temperature=temperature)\n",
    "    \n",
    "    raise ValueError(f\"Invalid model_provider: {model_provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f27bf8",
   "metadata": {},
   "source": [
    "#### Test the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1677ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_LLM = False\n",
    "llm = select_llm(model_provider='google')\n",
    "# llm = select_llm(model_provider='groq')\n",
    "# llm = select_llm(model_provider='ollama')\n",
    "\n",
    "if TEST_LLM:\n",
    "    resp = llm.invoke(\"What is superiority complex? Respond with a nicely structured & formatted answer!\")\n",
    "    print(resp)\n",
    "    \n",
    "    from IPython.display import display, Markdown\n",
    "    display(Markdown(resp.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a23b9b",
   "metadata": {},
   "source": [
    "## Define State Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b02d385",
   "metadata": {},
   "source": [
    "### Messages State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import Annotated, Sequence, TypedDict\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa6ca5",
   "metadata": {},
   "source": [
    "## Create Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f4f00",
   "metadata": {},
   "source": [
    "### Router Node\n",
    "This router will decide if the user has provided any Document/Website URL/YouTube URL. Depending on the type of URL it will call a function to load the document or just redirect the query to a RAG Agent for direct response generation if no URL is provided.\n",
    "\n",
    "### 💡 Idea Behind Router Agent\n",
    "The Router Agent will take the query and identify below mentioned features from the query:\n",
    " - User Query\n",
    " - URL/Path of a file/website/youtube-video\n",
    "\n",
    "And then it will return a structured output with the following informations:\n",
    " - `url`: URL/Path mentioned in the provided query (Can be `None` if absent)\n",
    " - `user_query`: The user query\n",
    " - `url_of`: `\"website\"`, `\"youtube_video\"`, `\"document\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Any, Optional\n",
    "from langchain_core.messages import AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9df094",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(\"\"\"\n",
    "You are an extraction agent. Your task is to return a JSON response in this exact format:\n",
    "\n",
    "{\n",
    "  \"user_query\": \"<EXACT user query WITHOUT any URLs or paths>\",\n",
    "  \"url\": \"<the full URL or local path if present, else null>\",\n",
    "  \"url_of\": \"<one of 'youtube_video', 'website', or 'document' if URL/path is present, else null>\"\n",
    "}\n",
    "\n",
    "⚠️ VERY STRICT RULES (follow them or your output is invalid):\n",
    "1. DO NOT paraphrase, correct, or modify the user's query — copy it EXACTLY as it appears.\n",
    "2. REMOVE all URLs and file paths from the `user_query`.\n",
    "3. IF a URL or file path exists, assign it to the `url` field and classify it using `url_of`.\n",
    "4. `url_of` MUST be one of: \"youtube_video\", \"website\", or \"document\". Never invent new types.\n",
    "5. IF no URL/path is found, both `url` and `url_of` must be null or omitted.\n",
    "\n",
    "====================\n",
    "EXAMPLES:\n",
    "\n",
    "# Example 1 (simple website URL):\n",
    "Input: How to use LangChain structured output? https://docs.langchain.com/docs/structured_outputs\n",
    "Output:\n",
    "{\n",
    "  \"user_query\": \"How to use LangChain structured output?\",\n",
    "  \"url\": \"https://docs.langchain.com/docs/structured_outputs\",\n",
    "  \"url_of\": \"website\"\n",
    "}\n",
    "\n",
    "# Example 2 (YouTube video link):\n",
    "Input: Summarize this video https://www.youtube.com/watch?v=dQw4w9WgXcQ\n",
    "Output:\n",
    "{\n",
    "  \"user_query\": \"Summarize this video\",\n",
    "  \"url\": \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n",
    "  \"url_of\": \"youtube_video\"\n",
    "}\n",
    "\n",
    "# Example 3 (file name with extension):\n",
    "Input: Convert file.txt to JSON\n",
    "Output:\n",
    "{\n",
    "  \"user_query\": \"Convert file.txt to JSON\",\n",
    "  \"url\": \"file.txt\",\n",
    "  \"url_of\": \"document\"\n",
    "}\n",
    "\n",
    "# Example 4 (multiple file paths — take only the one mentioned):\n",
    "Input: I saved it in ./notes/lecture1.md. Please summarize.\n",
    "Output:\n",
    "{\n",
    "  \"user_query\": \"Please summarize.\",\n",
    "  \"url\": \"./notes/lecture1.md\",\n",
    "  \"url_of\": \"document\"\n",
    "}\n",
    "\n",
    "# Example 5 (no URL or file path):\n",
    "Input: You should stop wasting your time\n",
    "Output:\n",
    "{\n",
    "  \"user_query\": \"You should stop wasting your time\"\n",
    "}\n",
    "\n",
    "# Example 6 (unclear context — do NOT assume):\n",
    "Input: Read this https://mystery.link/something\n",
    "Output:\n",
    "{\n",
    "  \"user_query\": \"Read this\",\n",
    "  \"url\": \"https://mystery.link/something\",\n",
    "  \"url_of\": \"website\"\n",
    "}\n",
    "\n",
    "# Example 7 (file path with Windows format):\n",
    "Input: Please check C:\\\\Users\\\\Me\\\\Desktop\\\\data.csv\n",
    "Output:\n",
    "{\n",
    "  \"user_query\": \"Please check\",\n",
    "  \"url\": \"C:\\\\Users\\\\Me\\\\Desktop\\\\data.csv\",\n",
    "  \"url_of\": \"document\"\n",
    "}\n",
    "====================\n",
    "\n",
    "🧠 TIP: If you are unsure about the type of the `url`, classify based on the extension or domain. If no clue, default to \"website\".\n",
    "\n",
    "NOW RETURN ONLY THE JSON OBJECT. Do NOT add explanations, comments, or markdown.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouterAgentResponse(BaseModel):\n",
    "    user_query: str = Field(description=(\n",
    "        \"The user's original query EXACTLY as it appears, without any modification, rewording, or interpretation.\\n\"\n",
    "        \"You MUST NOT include any URLs, file paths, or hyperlinks in this field — only the natural language query.\\n\"\n",
    "        \"Preserve the casing, punctuation, and wording. Do NOT fix typos or grammar.\"\n",
    "    ))\n",
    "    url: Optional[str] = Field(default=None, description=(\n",
    "        \"The exact URL or local document/file path mentioned in the user's input.\\n\"\n",
    "        \"If there is no URL or file path, leave this as null (do not fabricate one).\\n\"\n",
    "        \"Example: 'https://example.com/page', 'C:/Documents/myfile.txt', './notes.md'\"\n",
    "    ))\n",
    "    url_of: Optional[Literal[\"youtube_video\", \"website\", \"document\"]] = Field(default=None, description=(\n",
    "        \"The type of content the `url` field refers to:\\n\"\n",
    "        \"- 'youtube_video': if it's a YouTube video link\\n\"\n",
    "        \"- 'website': for general websites or web pages\\n\"\n",
    "        \"- 'document': for file paths (like .txt, .pdf, .md, etc.)\\n\"\n",
    "        \"If no URL/path is provided, this should be null.\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db004a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old RouterAgentResponse\n",
    "\n",
    "'''\n",
    "class RouterAgentResponse(BaseModel):\n",
    "    user_query: str = Field(description=\"The EXACT user query/question/statement present in the given text (anything other than the URL/Path).\")\n",
    "    # Optional Field\n",
    "    url: Optional[str] = Field(description=(\n",
    "            \"The URL or Local Document Path mentioned in the provided text.\"\n",
    "            \" No need to provide a value if the URL is absent in the given text.\"\n",
    "        ), default=None)\n",
    "    # Optional Field\n",
    "    url_of: Optional[Literal[\"youtube_video\", \"website\", \"document\"]] = Field(description=(\n",
    "        \"What the provided URL/Path represents.\\n\"\n",
    "        \"The values must be one of these:\\n\"\n",
    "        \" - youtube_video: If the provided URL represents a YouTube Video.\\n\"\n",
    "        \" - website: If the provided URL represents a website.\\n\"\n",
    "        \" - document: If the provided URL is a Path representing a document.\\n\"\n",
    "        \"No need to provide a value if the URL is absent in the given text.\"\n",
    "    ), default=None)\n",
    "# '''\n",
    "\n",
    "# Old Router Agent Node\n",
    "'''\n",
    "def router_agent_node(state: MessagesState) -> MessagesState:\n",
    "    user_query: str = state[\"messages\"][-1].content\n",
    "    tools_llm = llm.bind_tools(tools=document_loader_tools)\n",
    "    \n",
    "    system_prompt = SystemMessage(\n",
    "f\"\"\"You are a very helpful assistant. You have access to {len(document_loader_tools)} tools.\n",
    "\n",
    "Here is when to use which tool:\n",
    "    - load_youtube_transcript: To load an YouTube Video's transcript\n",
    "    - load_document: To load a Text/PDF document (can be a local path)\n",
    "    - load_webpage: To laod an WebPage\n",
    "    - pass_user_query: When you find no URL/Path in the user query\n",
    "\n",
    "Here is the user query: {user_query}\n",
    "\n",
    "Observe the user query and if you see any URL/Path of a file/document/YT Video/Website use the necessary tool to load it.\n",
    "If you see no URL then just use the `pass_user_query` tool to pass the query to the next Agent.\n",
    "\n",
    "You MUST use ONE of the above tools. DO NOT generate any extra text beyond what's instructed.\n",
    "    \"\"\")\n",
    "\n",
    "    ai_msg: AIMessage = tools_llm.invoke([system_prompt] + state[\"messages\"])\n",
    "    # Validate id the ai_msg has tool calls (IT MUST)\n",
    "    # ...\n",
    "    return {\"messages\": [ai_msg]}\n",
    "# '''\n",
    "\n",
    "\n",
    "def router_agent_node(state: MessagesState) -> MessagesState:\n",
    "    structured_llm = llm.with_structured_output(RouterAgentResponse)\n",
    "    _system_message = SystemMessage(\"\"\"You must STRICTLY follow the structure.\n",
    "You MUST provide the user query word for word (BUT MUST NOT INCLUDE the URLS/PATHS in `user_query`). DO NOT MODIFY OR IMPROVISE THE QUERY.\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "# Example Input 1: How to use the structured output?\n",
    "https://python.langchain.com/docs/concepts/structured_outputs/\n",
    "\n",
    "# Example Output 1:\n",
    "{\"user_query\":\"How to use the structured output?\",\"url\":\"https://python.langchain.com/docs/concepts/structured_outputs/\",\"url_of\":\"website\"}\n",
    "\n",
    "# Example Input 2: Convert this file into JSON format file.txt\n",
    "\n",
    "# Example Output 2:\n",
    "{\"user_query\":\"Convert this file into JSON format file.txt\", \"url\":\"file.txt\", \"url_of\":\"document\"}\n",
    "\n",
    "# Example Input 3: You should quit listening to music\n",
    "\n",
    "# Example Output 3:\n",
    "{\"user_query\":\"You should quit listening to music\"}\n",
    "\"\"\")\n",
    "    ai_msg: AIMessage = structured_llm.invoke([system_message, state[\"messages\"][-1]])\n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abffe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DOC_LOAD_ROUTER = False\n",
    "\n",
    "if TEST_DOC_LOAD_ROUTER:\n",
    "    queries = [\n",
    "        # Website URL\n",
    "        \"What is the model name mentioned?\\nhttps://build.nvidia.com/nvidia/llama-3_1-nemotron-51b-instruct\",\n",
    "        # YouTube URL\n",
    "        \"What do you see here?\\nhttps://www.youtube.com/watch?v=W3I3kAg2J7w&t=231s\",\n",
    "        # Local Document Path\n",
    "        \"Summarize this document: ~/data.json\",\n",
    "        # Just a normal Query\n",
    "        \"Why oranges are red and violates are blue?\",\n",
    "        \"This asdj/klrt/1234.py file appears to be corrupted. Can you read it?\"\n",
    "    ]\n",
    "\n",
    "    for i, query in enumerate(queries):\n",
    "        print(\"-\"*15, f\"Test {i + 1}\", \"*\"*15, end='\\n\\n')\n",
    "        response = router_agent_node(user_query=query)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "TEST_ROUTER_NODE = 1\n",
    "\n",
    "if TEST_ROUTER_NODE:\n",
    "    from langchain_core.messages import HumanMessage\n",
    "\n",
    "    queries = [\n",
    "        # Website URL\n",
    "        \"What is the model name mentioned?\\nhttps://build.nvidia.com/nvidia/llama-3_1-nemotron-51b-instruct\",\n",
    "        # YouTube URL\n",
    "        \"What do you see here?\\nhttps://www.youtube.com/watch?v=W3I3kAg2J7w&t=231s\",\n",
    "        # Local Document Path\n",
    "        \"Summarize this document: ~/data.json\",\n",
    "        # Just a normal Query\n",
    "        \"Why oranges are red and violates are blue?\",\n",
    "        \"This asdj/klrt/1234.py file appears to be corrupted. Can you read it?\"\n",
    "    ]\n",
    "\n",
    "    for query in queries:\n",
    "        print(\"Query:\", query)\n",
    "        state = MessagesState(messages=[HumanMessage(query)])\n",
    "        resp = router_agent_node(state)\n",
    "        print(resp[\"messages\"][0].model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1dea0",
   "metadata": {},
   "source": [
    "## Document Loader Function Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad3e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d4028b",
   "metadata": {},
   "source": [
    "### Chat Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_agent_node(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"A Chat Agent\"\"\"\n",
    "    system_prompt = SystemMessage(\"\"\"You are IntelliTube AI, a smart research parter for the user.\"\"\")\n",
    "    ai_msg: AIMessage = llm.invoke([system_prompt] + state[\"messages\"])\n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af9671",
   "metadata": {},
   "source": [
    "## Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "graph = (\n",
    "    StateGraph(state_schema=MessagesState)\n",
    "    .add_node(\"router_agent\", router_agent_node)\n",
    "    .add_node(\"tools\", ToolNode(tools=document_loader_tools))\n",
    "    .add_node(\"chat_agent\", chat_agent_node)\n",
    "    .add_edge(START, \"router_agent\")\n",
    "    .add_edge(\"router_agent\", \"tools\")\n",
    "    .add_edge(\"tools\", \"chat_agent\")\n",
    "    .add_edge(\"chat_agent\", END)\n",
    ")\n",
    "\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55daa84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf9978",
   "metadata": {},
   "source": [
    "## Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb496ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def chat_loop() -> None:\n",
    "    usr_msg: str = input(\">> \").strip()\n",
    "\n",
    "    while usr_msg.lower() != \"/exit\":\n",
    "        usr_msg = HumanMessage(usr_msg)\n",
    "        chat.add_message(usr_msg)\n",
    "        chat.chat_messages = agent.invoke({\"messages\": chat.chat_messages})[\"messages\"]\n",
    "        ai_msg: AIMessage = chat.chat_messages[-1]\n",
    "        ai_msg.pretty_print()\n",
    "        usr_msg: str = input(\">> \").strip()\n",
    "    chat.end_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d4e96d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchat_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mchat_loop\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m usr_msg = HumanMessage(usr_msg)\n\u001b[32m      8\u001b[39m chat.add_message(usr_msg)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m chat.chat_messages = \u001b[43magent\u001b[49m.invoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: chat.chat_messages})[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m ai_msg: AIMessage = chat.chat_messages[-\u001b[32m1\u001b[39m]\n\u001b[32m     11\u001b[39m ai_msg.pretty_print()\n",
      "\u001b[31mNameError\u001b[39m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intellitube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
