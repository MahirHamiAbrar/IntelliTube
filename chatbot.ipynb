{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2d383a",
   "metadata": {},
   "source": [
    "# Define StateSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17027ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import Annotated, Sequence, TypedDict\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ddd60",
   "metadata": {},
   "source": [
    "## Initialize a new Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e6456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ID: 8d336eb9-3a14-4281-a5e3-9d527fc1c3a3\n"
     ]
    }
   ],
   "source": [
    "from utils import ChatHistoryManager\n",
    "chat: ChatHistoryManager = ChatHistoryManager.new_chat()\n",
    "print(f\"Chat ID:\", chat.chat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5e8681",
   "metadata": {},
   "source": [
    "## Initialize the RAG System\n",
    "Using `TextDocumentRAG()` from `intellitube.rag` module automatically initializes `Qdrant` client as Vector Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdcf9dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-08 15:46:10.099\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mintellitube.rag\u001b[0m:\u001b[36minit_vector_store\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mCreaing Client...\u001b[0m\n",
      "\u001b[32m2025-07-08 15:46:10.111\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mintellitube.rag\u001b[0m:\u001b[36minit_vector_store\u001b[0m:\u001b[36m73\u001b[0m - \u001b[34m\u001b[1mCreaing vector store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from intellitube.rag import TextDocumentRAG\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_rag = TextDocumentRAG(\n",
    "    path_on_disk=chat.chat_dirpath,\n",
    "    collection_path_on_disk=os.path.join(chat.chat_dirpath, \"collection\"),\n",
    "    collection_name=chat.chat_id,\n",
    ")\n",
    "\n",
    "def add_to_vdb(docuemnts: List[Document]) -> None:\n",
    "    # convert to a list of document(s) if not already!\n",
    "    if type(docuemnts) == Document:\n",
    "        docuemnts = [docuemnts]\n",
    "    \n",
    "    document_rag.add_documents(\n",
    "        docuemnts, split_text=True,\n",
    "        split_config={\n",
    "            \"chunk_size\": 512,\n",
    "            \"chunk_overlap\": 128\n",
    "        },\n",
    "        skip_if_collection_exists=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0781f4",
   "metadata": {},
   "source": [
    "## Create Document Loader Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8ebb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e792db4",
   "metadata": {},
   "source": [
    "### 1. Add YouTube Videos to the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd262d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    YTContentData,\n",
    "    webvtt_2_str,\n",
    "    download_youtube_audio_or_transcript,\n",
    ")\n",
    "\n",
    "test_url = \"https://www.youtube.com/watch?v=W3I3kAg2J7w&t=231s\"\n",
    "\n",
    "@tool\n",
    "def load_youtube_transcript(youtube_url: str) -> str:\n",
    "    \"\"\"Load the given YouTube video's transcript to the vector database.\n",
    "    It is required to answer user-queries based on the the Transcript context.\"\"\"\n",
    "    \n",
    "    # download the youtube transcript (or audio if transcript not available)\n",
    "    yt_video_data: YTContentData = download_youtube_audio_or_transcript(\n",
    "        video_url=youtube_url,\n",
    "    )\n",
    "\n",
    "    # convert the WEBVTT format trancript to a plain text string\n",
    "    vtt_str = webvtt_2_str(vtt_file_path=yt_video_data.transcript_path)\n",
    "    \n",
    "    print(vtt_str[:100])    # print first 100 characters\n",
    "\n",
    "    # add the transcript-string to the vector database\n",
    "    add_to_vdb(Document(vtt_str))\n",
    "    return \"YouTube Video Transcript has been loaded successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac44794",
   "metadata": {},
   "source": [
    "### 2. Add PDF/Text Documents to the Vector Dataabse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c33961ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "@tool\n",
    "def load_document(document_path: str) -> None:\n",
    "    \"\"\"Load the given Document's content to the vector database.\n",
    "    It is required to answer user-queries based on the the Document context.\"\"\"\n",
    "    \n",
    "    ext = os.path.splitext(document_path)[1][1:].lower()\n",
    "    documents: List[Document]\n",
    "\n",
    "    if ext == 'pdf':\n",
    "        documents = PyPDFLoader(document_path).load()\n",
    "    elif ext == 'txt':\n",
    "        with open(document_path, 'r') as file:\n",
    "            documents = [Document(\n",
    "                page_content=file.read(),\n",
    "                metadata={ \"source\": document_path }\n",
    "            )]\n",
    "    else:\n",
    "        return f\"Unsupported filetype: {ext}!\"\n",
    "    \n",
    "    add_to_vdb(documents)\n",
    "    return \"The document has been loaded successfully!\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8cdd0",
   "metadata": {},
   "source": [
    "### 3. Add WebPages as Documents to the Vector Dataabse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d08fccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "@tool\n",
    "def load_webpage(webpage_url: str) -> None:\n",
    "    \"\"\"Load the given WebSite's content to the vector database.\n",
    "    It is required to answer user-queries based on the the WebPage's context.\"\"\"\n",
    "\n",
    "    add_to_vdb(WebBaseLoader(webpage_url).load())\n",
    "    return \"The webpage has been loaded successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c1f488",
   "metadata": {},
   "source": [
    "#### Finally, compile a list of the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e63e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='load_youtube_transcript', description=\"Load the given YouTube video's transcript to the vector database.\\n    It is required to answer user-queries based on the the Transcript context.\", args_schema=<class 'langchain_core.utils.pydantic.load_youtube_transcript'>, func=<function load_youtube_transcript at 0x7f45cba9e020>),\n",
      " StructuredTool(name='load_document', description=\"Load the given Document's content to the vector database.\\n    It is required to answer user-queries based on the the Document context.\", args_schema=<class 'langchain_core.utils.pydantic.load_document'>, func=<function load_document at 0x7f45cba9e7a0>),\n",
      " StructuredTool(name='load_webpage', description=\"Load the given WebSite's content to the vector database.\\n    It is required to answer user-queries based on the the WebPage's context.\", args_schema=<class 'langchain_core.utils.pydantic.load_webpage'>, func=<function load_webpage at 0x7f45cba9f560>)]\n"
     ]
    }
   ],
   "source": [
    "tools = [load_youtube_transcript, load_document, load_webpage]\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
